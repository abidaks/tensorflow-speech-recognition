{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.compat.v1.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.compat.v1.keras.callbacks import TensorBoard\n",
    "from callbacks import ConfusionMatrixCallback\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from classes import get_classes\n",
    "from utils import data_gen\n",
    "from IPython import embed  # noqa\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "K.set_session(sess)\n",
    "data_dirs = ['data/train/audio']\n",
    "output_representation = 'raw'\n",
    "sample_rate = 16000\n",
    "batch_size = 384\n",
    "classes = get_classes(wanted_only=False, extend_reversed=False)\n",
    "#classes =  'sheila nine stop bed four six down bird marvin cat off right seven eight up three happy go zero on wow dog yes five one tree house two left no' # noqa\n",
    "#classes = classes.split(' ')\n",
    "model_settings = prepare_model_settings(\n",
    "    label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "    clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "    dct_coefficient_count=80, num_log_mel_features=60,\n",
    "    output_representation=output_representation)\n",
    "ap = AudioProcessor(\n",
    "    data_dirs=data_dirs, wanted_words=classes,\n",
    "    silence_percentage=13.0, unknown_percentage=60.0,\n",
    "    validation_percentage=10.0, testing_percentage=0.0,\n",
    "    model_settings=model_settings,\n",
    "    output_representation=output_representation)\n",
    "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training',\n",
    "               pseudo_frequency=0.6)\n",
    "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation',\n",
    "                   pseudo_frequency=0.0)\n",
    "model = speech_model('conv_1d_time_sliced_with_attention', \n",
    "    model_settings['fingerprint_size'] if output_representation != 'raw' else model_settings['desired_samples'],  # noqa\n",
    "    num_classes=model_settings['label_count'], **model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  ConfusionMatrixCallback(\n",
    "      val_gen, ap.set_size('validation') // batch_size,\n",
    "      wanted_words=prepare_words_list(get_classes(wanted_only=True)),\n",
    "      all_words=prepare_words_list(classes),\n",
    "      label2int=ap.word_to_index),\n",
    "  ReduceLROnPlateau(monitor='val_categorical_accuracy', mode='max',\n",
    "                    factor=0.5, patience=4, verbose=1, min_lr=1e-5),\n",
    "  TensorBoard(log_dir='logs_210'),\n",
    "  ModelCheckpoint(\n",
    "      'ep-{epoch:03d}-vl-{loss:.4f}.hdf5',\n",
    "      save_best_only=True, monitor='val_categorical_accuracy',\n",
    "      mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, steps_per_epoch=ap.set_size('training') // batch_size,\n",
    "      epochs=100, verbose=1, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch=ap.set_size('training') // batch_size,\n",
    "      epochs=100, verbose=1, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = model.evaluate(val_gen, ap.set_size('validation') // batch_size)\n",
    "print(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"speech_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = prepare_words_list(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sample_rate = librosa.load(\"audios/check.wav\", sr = 16000)\n",
    "predictData = librosa.resample(sample, 16000, 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(predictData.reshape(1,16000))\n",
    "\n",
    "maxProb = max(prob[0])\n",
    "probClass = all_classes[np.argmax(prob[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxProb)\n",
    "print(probClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
